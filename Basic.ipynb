{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import (AIMessage, HumanMessage, SystemMessage)\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_core.documents import Document\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Monday comes Tuesday.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    openai_api_base=\"https://api.xiaoai.plus/v1\",\n",
    "    openai_api_key= os.getenv('OPENAI_API_KEY'),\n",
    "    temperature=0.3\n",
    ")\n",
    "res = llm.invoke(\"What is after Monday?\")\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/st_lc/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here's a simple Python script that trains a neural network on simulated data using the Keras library:\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "from keras.models import Sequential\n",
      "from keras.layers import Dense\n",
      "\n",
      "# Generate simulated data\n",
      "np.random.seed(0)\n",
      "X = np.random.rand(100, 2)\n",
      "y = np.random.randint(2, size=100)\n",
      "\n",
      "# Define the model architecture\n",
      "model = Sequential()\n",
      "model.add(Dense(4, input_dim=2, activation='relu'))\n",
      "model.add(Dense(1, activation='sigmoid'))\n",
      "\n",
      "# Compile the model\n",
      "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
      "\n",
      "# Train the model\n",
      "model.fit(X, y, epochs=10, batch_size=10)\n",
      "\n",
      "# Evaluate the model\n",
      "loss, accuracy = model.evaluate(X, y)\n",
      "print(f'Loss: {loss}, Accuracy: {accuracy}')\n",
      "```\n",
      "\n",
      "In this script, we first generate simulated data using `np.random.rand()` and `np.random.randint()`. The input data `X` is a 2-dimensional array of shape (100, 2), and the target labels `y` are binary values.\n",
      "\n",
      "Next, we define the model architecture using the `Sequential` class from Keras. The model consists of two dense layers with ReLU activation in the hidden layer and sigmoid activation in the output layer.\n",
      "\n",
      "We then compile the model using the `compile()` method, specifying the loss function, optimizer, and metrics to track during training.\n",
      "\n",
      "After that, we train the model using the `fit()` method, passing in the input data `X` and target labels `y`. We specify the number of epochs (iterations over the entire dataset) and the batch size (number of samples per gradient update).\n",
      "\n",
      "Finally, we evaluate the trained model using the `evaluate()` method, which returns the loss and accuracy on the input data `X` and target labels `y`.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content = \"You are an expert data scientist\"),\n",
    "    HumanMessage(content = \"Write a very simple python script that trains a neural network on simulated data\")\n",
    "]\n",
    "response = llm(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't you ever iron an Irish flag?\n",
      "\n",
      "Because you don't want to press your luck!\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables = ['topic'],\n",
    "    template = \"\"\"Please tell me a joke about {topic} with 50 words.\"\"\"\n",
    ")\n",
    "response = llm(prompt.format(topic=\"Irish\"))\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't Irish people play hide and seek?\n",
      "\n",
      "Because someone always spots them at the pub!\n"
     ]
    }
   ],
   "source": [
    "chain_one = prompt | llm | StrOutputParser()\n",
    "response1 = chain_one.invoke({\"topic\": \"Irish\"})\n",
    "print(response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, it is a punny joke! It plays on the words \"Dublin\" (the capital city of Ireland) and \"doubling\" the tempo in music.\n"
     ]
    }
   ],
   "source": [
    "prompt_second = PromptTemplate(\n",
    "    input_variables = ['joke'],\n",
    "    template = \"\"\"Is this {joke} funny?\"\"\"\n",
    ")\n",
    "overall_chain = {\"joke\": chain_one} | prompt_second | llm | StrOutputParser()\n",
    "response2 = overall_chain.invoke({\"topic\": \"Irish\"})\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding & Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a faraway kingdom, there lived a kind-hearted princess named Aurora. She had a heart as pure as gold and a smile that could light up the darkest of rooms. Aurora was loved by her people and admired for her compassion towards everyone, from the humblest of villagers to the grandest of nobles.\n",
      "\n",
      "One day, a terrible curse fell upon the kingdom. A wicked sorceress named Morgana cast a spell that plunged the land into eternal darkness. Desperate to save her people, Princess Aurora embarked on a perilous journey to find the legendary Crystal of Light, the only object powerful enough to break the curse.\n",
      "\n",
      "With unwavering determination, Aurora traveled through treacherous forests and crossed vast oceans, facing countless obstacles along the way. She encountered mythical creatures, who became her loyal companions, and wise old sages, who guided her with their wisdom. Despite the challenges, Aurora never lost hope.\n",
      "\n",
      "Finally, after months of searching, Aurora reached the Cave of Enchantment, where the Crystal of Light was said to be hidden. Inside, she faced Morgana in a fierce battle of good versus evil. With her pure heart and unwavering courage, Aurora managed to defeat the sorceress and retrieve the crystal.\n",
      "\n",
      "As Aurora held the Crystal of Light in her hands, a blinding radiance filled the cave, banishing the darkness that had plagued the kingdom for so long. The curse was broken, and the land was bathed in a warm, golden light once again.\n",
      "\n",
      "The people rejoiced, celebrating their beloved princess who had saved them all. Aurora's kindness and bravery had not only restored the kingdom but had also touched the hearts of everyone she encountered. From that day forward, her name became synonymous with hope and love.\n",
      "\n",
      "Princess Aurora continued to rule with compassion and grace, ensuring the prosperity and happiness of her people. She became a symbol of unity and inspiration, reminding everyone that even in the darkest of times, a single act of kindness can bring forth a world of light.\n",
      "\n",
      "And so, the tale of Princess Aurora and the Crystal of Light was passed down through generations, reminding all who heard it of the power of love, courage, and the beauty that lies within every soul.\n"
     ]
    }
   ],
   "source": [
    "prompt3 = PromptTemplate(\n",
    "    input_variables = [\"story\"],\n",
    "    template=\"\"\"please make up a beautiful story based on topic of {story} within 300 words\"\"\"\n",
    ")\n",
    "\n",
    "story_example = llm(prompt3.format(story = 'princess'))\n",
    "print(story_example.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Once upon a time, in a faraway kingdom, there lived a kind-hearted princess named Aurora. She had a'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#text splitter\n",
    "test_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap = 0\n",
    ")\n",
    "\n",
    "texts = test_splitter.create_documents([story_example.content])\n",
    "texts[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.011465082, -0.03161949, -0.014830855]\n"
     ]
    }
   ],
   "source": [
    "#embedding\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    openai_api_base=\"https://api.xiaoai.plus/v1\",\n",
    "    openai_api_key= os.getenv('OPENAI_API_KEY'),\n",
    ")\n",
    "query_result = embeddings.embed_query(texts[0].page_content)\n",
    "print(query_result[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5540bd3b-05a4-428b-8a37-687770bc626d',\n",
       " '2bfd2a37-3191-4387-b0b9-56f152ed0b0e',\n",
       " '1ac533af-ddc7-4e88-a0a2-abc08f9559cd',\n",
       " '74c0d8fd-53f5-489c-9d74-68eb0ffc9056',\n",
       " '468bfc84-a736-4740-809a-a9559477e6bc',\n",
       " '18a0a2fd-0305-4dc5-9a80-5ba410b41d20',\n",
       " '650ac681-7730-4b6f-b611-114b222671d2',\n",
       " 'f94139b1-42b3-4fb6-bb71-86a868dcc8ee',\n",
       " '5ce49393-7170-4f10-b559-a5b4ea4a0f4b',\n",
       " '7472c46d-3809-4883-a717-53d6a8f75b52',\n",
       " 'd9abc928-1c7b-4b61-8cae-89b8d447fa02',\n",
       " '0edc670d-e5db-4daf-afe3-94e386ec73f0',\n",
       " '7b892ab6-8643-4fb9-8664-1c459635c0ec',\n",
       " 'bdffbbef-d5c7-4e1f-9be2-5c388ae0a791',\n",
       " 'ef75e919-fb34-42a0-9fa4-25c854858141',\n",
       " '64a005cd-e4d7-4b9a-9ea9-48e42ce1c215',\n",
       " '6b53acf0-6b9b-4288-abc4-8015a9260071',\n",
       " '35021b53-6553-495e-81f4-2a8b580e41cc',\n",
       " '8a6ce28b-7c18-4cda-9bdd-0c934af4ea5e',\n",
       " 'f676a968-a71c-4067-ac99-b9d8b7cd2acd',\n",
       " 'fe818de2-3ed2-4615-a8e2-5c9bf3eb9244',\n",
       " '9bce7c45-b27e-48bf-bcdb-dd92a04265cd',\n",
       " '360ef897-f4ee-401f-8655-37b25103ef24',\n",
       " '6dd14fbb-0121-44c7-9dda-76bcce01d080',\n",
       " '4cd64d7f-c5bb-4c04-a219-6ce1d7a11de6',\n",
       " 'ede4ed02-50bd-4984-8c96-0403c3c75931',\n",
       " 'e8bac770-59e8-4b23-99db-d63eea4ec7a3',\n",
       " '03246fa2-e047-4fb3-bd8f-169183646f7d']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pinecone\n",
    "pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "index_name = 'langchain-quickstart-today'\n",
    "\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embeddings)\n",
    "vector_store.add_documents(documents=texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Document(page_content='peace and prosperity to the kingdom.'), 0.848613918)\n",
      "(Document(page_content='the cave, and the curse was lifted from the kingdom. The land was once again bathed in sunshine,'), 0.834380031)\n"
     ]
    }
   ],
   "source": [
    "query = \"what happend in that kingdom?\"\n",
    "results = vector_store.similarity_search_with_score(query=query, k=2)\n",
    "for res in results:\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
